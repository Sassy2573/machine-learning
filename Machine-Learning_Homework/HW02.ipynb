{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "822866e1",
   "metadata": {},
   "source": [
    "## 作业任务\n",
    "1. ​2-1 Phoneme Classification（8分/10分）\n",
    "    - ​​任务介绍​​：可能涉及音素（语音单位）的分类任务。\n",
    "    - ​​数据集与数据格式​​：需注意数据的具体结构和特征。\n",
    "    - ​​Kaggle提交格式​​：需按照Kaggle平台的要求提交结果（如文件格式、命名规范等）。\n",
    "    - ​​评分标准​​：可能基于分类准确率或其他指标\n",
    "2. ​​2-2 Hessian Matrix（2分/10分）​\n",
    "    - 任务介绍​​：可能要求计算或分析Hessian矩阵（二阶导数矩阵）的性质\n",
    "    - 梯度范数/最小比值​​：可能涉及优化问题中的梯度分析\n",
    "    - ​​NTU Cool提交​​：需通过指定平台提交（注意格式要求）\n",
    "    - 评分标准​​：可能关注数学推导或结果的正确性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e53c0",
   "metadata": {},
   "source": [
    "## 任务分析\n",
    "1. 任务描述\n",
    "    - 任务类型：多类分类（Multiclass classification）\n",
    "    - 目标：从语言信号中逐渐预测音素\n",
    "    - 输入/输出：\n",
    "        - 输入：语言波形\n",
    "        - 输出：每一帧对应的音素标签序列\n",
    "2. 音素概念\n",
    "    - 定义：音素是语音中最小的、有区别的语言单位，如英语中的“b”、“d”等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c3f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Size of training data: (1229932, 429)\n",
      "Size of testing data: (451552, 429)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "print('Loading data ...')\n",
    "\n",
    "data_root='../../Data/timit_11/'\n",
    "train = np.load(data_root + 'train_11.npy')\n",
    "train_label = np.load(data_root + 'train_label_11.npy')\n",
    "test = np.load(data_root + 'test_11.npy')\n",
    "\n",
    "print('Size of training data: {}'.format(train.shape))\n",
    "print('Size of testing data: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017e966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TIMITDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = torch.from_numpy(X.astype(np.float32))\n",
    "        if y is not None:\n",
    "            y = y.astype(np.int32)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115c7d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (983945, 429)\n",
      "Size of validation set: (245987, 429)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VAL_RATIO = 0.2\n",
    "\n",
    "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
    "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
    "print('Size of training set: {}'.format(train_x.shape))\n",
    "print('Size of validation set: {}'.format(val_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68df861",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = TIMITDataset(train_x, train_y)\n",
    "val_set = TIMITDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3380e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del train, train_label, train_x, train_y, val_x, val_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb8c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(429, 1024)\n",
    "        self.layer2 = nn.Linear(1024, 512)\n",
    "        self.layer3 = nn.Linear(512, 128)\n",
    "        self.out = nn.Linear(128, 39) \n",
    "\n",
    "        self.act_fn = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff4251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check device\n",
    "def get_device():\n",
    "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f851e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb15104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fix random seed for reproducibility\n",
    "same_seeds(0)\n",
    "\n",
    "# get device \n",
    "device = get_device()\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# training parameters\n",
    "num_epoch = 20               # number of training epoch\n",
    "learning_rate = 0.0001       # learning rate\n",
    "\n",
    "# the path where checkpoint saved\n",
    "model_path = './model.ckpt'\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a79b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/020] Train Acc: 0.467302 Loss: 1.811661 | Val Acc: 0.567428 loss: 1.433065\n",
      "saving model with acc 0.567\n",
      "[002/020] Train Acc: 0.594383 Loss: 1.330665 | Val Acc: 0.628639 loss: 1.211098\n",
      "saving model with acc 0.629\n",
      "[003/020] Train Acc: 0.644506 Loss: 1.154064 | Val Acc: 0.660421 loss: 1.101215\n",
      "saving model with acc 0.660\n",
      "[004/020] Train Acc: 0.672217 Loss: 1.052246 | Val Acc: 0.676300 loss: 1.038718\n",
      "saving model with acc 0.676\n",
      "[005/020] Train Acc: 0.691348 Loss: 0.983103 | Val Acc: 0.685154 loss: 1.001852\n",
      "saving model with acc 0.685\n",
      "[006/020] Train Acc: 0.705616 Loss: 0.931955 | Val Acc: 0.689301 loss: 0.984177\n",
      "saving model with acc 0.689\n",
      "[007/020] Train Acc: 0.716345 Loss: 0.891687 | Val Acc: 0.694516 loss: 0.964627\n",
      "saving model with acc 0.695\n",
      "[008/020] Train Acc: 0.725881 Loss: 0.857907 | Val Acc: 0.697720 loss: 0.951889\n",
      "saving model with acc 0.698\n",
      "[009/020] Train Acc: 0.733718 Loss: 0.829495 | Val Acc: 0.696687 loss: 0.949866\n",
      "[010/020] Train Acc: 0.741151 Loss: 0.803701 | Val Acc: 0.699374 loss: 0.944832\n",
      "saving model with acc 0.699\n",
      "[011/020] Train Acc: 0.748050 Loss: 0.781106 | Val Acc: 0.697773 loss: 0.946494\n",
      "[012/020] Train Acc: 0.753793 Loss: 0.760380 | Val Acc: 0.702830 loss: 0.938236\n",
      "saving model with acc 0.703\n",
      "[013/020] Train Acc: 0.759404 Loss: 0.741234 | Val Acc: 0.700456 loss: 0.945627\n",
      "[014/020] Train Acc: 0.764573 Loss: 0.723574 | Val Acc: 0.702159 loss: 0.942118\n",
      "[015/020] Train Acc: 0.769472 Loss: 0.707325 | Val Acc: 0.704427 loss: 0.936154\n",
      "saving model with acc 0.704\n",
      "[016/020] Train Acc: 0.773688 Loss: 0.691314 | Val Acc: 0.701736 loss: 0.945713\n",
      "[017/020] Train Acc: 0.778676 Loss: 0.676633 | Val Acc: 0.701586 loss: 0.953081\n",
      "[018/020] Train Acc: 0.783107 Loss: 0.662425 | Val Acc: 0.699663 loss: 0.963290\n",
      "[019/020] Train Acc: 0.786396 Loss: 0.649180 | Val Acc: 0.700078 loss: 0.957681\n",
      "[020/020] Train Acc: 0.790644 Loss: 0.636623 | Val Acc: 0.699732 loss: 0.964269\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train() # set the model to training mode\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs) \n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                batch_loss = criterion(outputs, labels) \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "            \n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += batch_loss.item()\n",
    "\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "\n",
    "# if not validating, save the last epoch\n",
    "if len(val_set) == 0:\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('saving model at last epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14fb62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenYL\\AppData\\Local\\Temp\\ipykernel_10592\\2373171232.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create testing dataset\n",
    "test_set = TIMITDataset(test, None)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = Classifier().to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90e3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "model.eval() # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "\n",
    "        for y in test_pred.cpu().numpy():\n",
    "            predict.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30ef440",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(predict):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8febd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6094de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa96d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classifier.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "dummy_input = torch.randn(1, 429)  # 假设batch_size=1\n",
    "output = model(dummy_input)\n",
    "\n",
    "make_dot(output, params=dict(model.named_parameters())).render(\"classifier\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6890fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
